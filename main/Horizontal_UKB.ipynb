{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1swZv5QP3Ac"
   },
   "source": [
    "# Proteomic Insights into Inflammatory Bowel Disease biomarker discovery in the UK Biobank.\n",
    "\n",
    "\n",
    "**Authors:**\n",
    "Francisco Salamanca¹, David Gomez², Daniel Bonilla³\n",
    "\n",
    "**Affiliations:**\n",
    "1. MSc Bioinformatics Student, Universidad Nacional de Colombia  \n",
    "2. MSc Industrial Engineering Student, Universidad Nacional de Colombia \n",
    "3. System Engineering Student, Universidad Nacional de Colombia\n",
    "\n",
    "\n",
    "**Objective:**\n",
    "The primary objective of this project is to develop a predictive model for inflammatory bowel disease (IBD) relapse and new onset, leveraging longitudinal proteomics data from the UK Biobank. The model aims to capture early signals of disease activity or onset, particularly focusing on proteomic biomarkers trajectories.\n",
    "\n",
    "**Background:**\n",
    "IBD is a chronic and relapsing inflammatory disorder that includes Crohn’s disease and ulcerative colitis. Despite advances in treatment, predicting disease progression and relapse remains a major clinical challenge. Multi-omics profiling provides a promising avenue for identifying molecular signatures associated with IBD activity over time.\n",
    "\n",
    "**Approach:**\n",
    "- **Data**: UK Biobank data including proteomics (Olink panels), genomics, and clinical data.\n",
    "- **Participants**: Individuals with multiple time-point measurements for proteomics and relevant metadata.\n",
    "- **Outcome Variables**: \n",
    "    - IBD diagnosis and subtypes (if available),\n",
    "    - Relapse indicators or clinical events related to disease progression.\n",
    "\n",
    "**Methods:**\n",
    "- Preprocessing of datasets and harmonization of participant identifiers.\n",
    "- Extraction of **relevant** clinical covariates (e.g., medication use, smoking, alcohol, BMI) from the datasets.\n",
    "- Identification of temporal patterns and trajectory modeling of proteomic profiles.\n",
    "- Machine learning models (e.g., random forest, survival models, neural networks) adjusted for medical variables known to be associated with IBD.\n",
    "- Validation using cross-validation and/or independent subsets of the data.\n",
    "\n",
    "**Expected Results:**\n",
    "- Identification of omics-based biomarkers predictive of IBD relapse or future diagnosis.\n",
    "- Insights into the molecular mechanisms underlying disease progression.\n",
    "- A prototype predictive tool to aid in risk stratification and early clinical intervention.\n",
    "\n",
    "**Deliverables:**\n",
    "- A cleaned longitudinal dataset.\n",
    "- Statistical and machine learning models with performance metrics.\n",
    "- Visualizations of longitudinal profiles and feature importance.\n",
    "- Final report and optional manuscript draft for publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5S1bC3yRypZ",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Package Import and Path Configuration\n",
    "This section imports all required packages and defines the file paths needed for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew\n",
    "import math\n",
    "import src.visualizaciones as visualizaciones\n",
    "import src.limpieza as limpieza\n",
    "import src.transformaciones as transformaciones\n",
    "import src.modelos as modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/UK_BIOBANK_DATA\" \n",
    "path_graphs = \"outputs/graphs\" \n",
    "path_results = \"outputs/results\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yY1MKSxRRxK1",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Loading and Initial Exploration\n",
    "This section loads UK Biobank data modules by data type, each containing a unique identifier who refers to the other tables. A preliminary exploration is conducted to examine the structure and key features of the datasets.\n",
    "\n",
    "The Preprocessing of each of those tables are found in indivudual notebooks at /home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Proteomics  \n",
    "*This table includes protein expression levels measured across all individuals.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charge dataframes\n",
    "#Proteomics\n",
    "Proteomics_df = pd.read_csv(os.path.join(path, \"olink_data.tsv\"), sep=\"\\t\")\n",
    "Proteomics_chars_df = pd.read_csv(os.path.join(path, \"Proteomics_modified_data/olink_chars_table.tsv\"), sep=\"\\t\")\n",
    "\n",
    "#Crear columna con el nombre de las proteinas y #ordenar df\n",
    "cols = Proteomics_chars_df.columns.tolist()\n",
    "Proteomics_chars_df.insert(cols.index(\"ValueType\"), \"pname\",Proteomics_chars_df[\"Field\"].str.split(\";\").str[0])\n",
    "Proteomics_chars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCePs4bteGyq"
   },
   "outputs": [],
   "source": [
    "#Encuentra columnas duplicadas y eliminalas\n",
    "Proteomics_df = Proteomics_df.loc[:, ~Proteomics_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibgKzM-58wDR"
   },
   "outputs": [],
   "source": [
    "##Cambiar las columnas de Olink_proteomics, pasarlas de formato: FieldID_instance a formato: Nombre_instancia\n",
    "\n",
    "# Extraer columnas (excepto 'eid')\n",
    "original_cols = Proteomics_df.columns.tolist()\n",
    "data_cols = original_cols[1:]\n",
    "\n",
    "# Extraer FieldID y instance de los nombres de columna\n",
    "fids = [int(re.search(r'f_(\\d+)_', col).group(1)) if re.search(r'f_(\\d+)_', col) else None for col in data_cols]\n",
    "instances = [re.sub(r'f_\\d+_|f_NA_', '', col) for col in data_cols]\n",
    "\n",
    "# Crear DataFrame auxiliar\n",
    "col_df = pd.DataFrame({'old': data_cols, 'fids': fids, 'instance': instances})\n",
    "\n",
    "# Unir con olinkchar para obtener los 'pname'\n",
    "col_df = col_df.merge(Proteomics_chars_df[['FieldID', 'pname']], left_on='fids', right_on='FieldID', how='left')\n",
    "\n",
    "# Crear nuevos nombres\n",
    "col_df['newname'] = col_df['pname'] + '_' + col_df['instance']\n",
    "\n",
    "# Asignar nuevos nombres de columna\n",
    "Proteomics_df.columns = ['eid'] + col_df['newname'].tolist()\n",
    "\n",
    "# Obtener la columna 'eid', que contiene los IDs de los participantes\n",
    "eids = Proteomics_df['eid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "jTViRwbI9X2L",
    "outputId": "83ab6219-6c07-41ab-83b0-873d66f04799"
   },
   "outputs": [],
   "source": [
    "Proteomics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vgB8J_K7-74F",
    "outputId": "be4ad0be-0f67-4650-d459-36fed3d071c1"
   },
   "outputs": [],
   "source": [
    "# Convert column names to strings\n",
    "Proteomics_df.columns = Proteomics_df.columns.astype(str)\n",
    "\n",
    "# Hay proteinas que no estan en las 4 sets longitudinales, por lo que se tiene que decidir o tener en cuenta!!!\n",
    "# Ejemplo:\n",
    "filtered_columns = [col for col in Proteomics_df.columns if col.startswith('CD6')]\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Phenotypes  \n",
    "*This table contains data on participants lifestyle habits and behavioral traits.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charge the dataframes\n",
    "phenotypes_df = pd.read_csv(os.path.join(path,\"phenotype_data.tsv\"), sep=\"\\t\")\n",
    "phenotypes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "l1DFFs2LGO1O",
    "outputId": "78b48310-395d-4306-ecb4-d0c8088575e1"
   },
   "outputs": [],
   "source": [
    "##Phenotypes DF ####\n",
    "##¿Cuales fenotipos estan mas associados a la condicion de tener ibd?\n",
    "#Se sabe por bibliografia que: smoking y alcohol\n",
    "\n",
    "# Seleccionar columnas cuyos nombres contienen _20116_ o _20117_\n",
    "phenodata_esential_df = phenotypes_df.filter(regex=r'eid|_20116_|_20117_', axis=1)\n",
    "\n",
    "# Crear un diccionario para renombrar columnas\n",
    "new_columns = {\n",
    "    col: col.replace('f_20116', 'Smoking').replace('f_20117', 'Alcohol').removesuffix('_0')\n",
    "    for col in phenodata_esential_df.columns\n",
    "}\n",
    "\n",
    "# Renombrar las columnas\n",
    "phenodata_esential_df.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "# Mostrar el DataFrame resultante\n",
    "phenodata_esential_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar -3 por np.nan en columnas numéricas, excepto 'eid'\n",
    "cols_to_replace = phenodata_esential_df.select_dtypes(include='number').columns.drop('eid', errors='ignore')\n",
    "phenodata_esential_df[cols_to_replace] = phenodata_esential_df[cols_to_replace].replace(-3, np.nan)\n",
    "phenodata_esential_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etnicity\n",
    "*This table contains Etnicity info of the different participants according to the genetics. is coded in a PCA base*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charge dataframes\n",
    "etnicidad_df = pd.read_csv(os.path.join(path,\"genomics_data.tsv\"), sep=\"\\t\")\n",
    "etnicidad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar por el id \"Genetic principal components (22009)\", el campo el cual me indica etnicidad \n",
    "\n",
    "etnicidad_df.columns = etnicidad_df.columns.str.replace(\"f_22009_0\", \"PC\", regex=True)\n",
    "etnicidad_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Physical Measures  \n",
    "*This table provides clinical measurements of the participants, including weight, height, and related physical data.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Charge dataframes\n",
    "physical_measures_df = pd.read_csv(os.path.join(path, \"Physical_measures_data.tsv\"), sep=\"\\t\")\n",
    "physical_measures_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleccionar columnas relevantes de physical_measures_df\n",
    "columns_to_keep = ['eid'] + [col for col in physical_measures_df.columns if re.search(r'_48_|_49_|_23104_|_23100_|_23101_|_23102_', col)]\n",
    "phys_esential = physical_measures_df[columns_to_keep].copy()\n",
    "\n",
    "\n",
    "# 2. Calcular WHR para cada visita (0 a 3), Crear una nueva columna 'WHR' para cada punto, donde sea la relacion entre la cintura y la cadera\n",
    "for i in range(4):\n",
    "    phys_esential[f'WHR_{i}'] = phys_esential[f'f_48_{i}_0'] / phys_esential[f'f_49_{i}_0']\n",
    "\n",
    "# 3. Renombrar columnas\n",
    "phys_esential.columns = (\n",
    "    phys_esential.columns\n",
    "    .str.replace('f_48', 'Waist', regex=True)\n",
    "    .str.replace('f_49', 'Hip', regex=True)\n",
    "    .str.replace('f_23104', 'BMI', regex=True)\n",
    "    .str.replace('f_23100', 'wFatMass', regex=True)\n",
    "    .str.replace('f_23101', 'wFatFreeMass', regex=True)\n",
    "    .str.replace('f_23102', 'wWaterMass', regex=True)\n",
    "    .str.replace('_0$', '', regex=True)\n",
    "    .str.replace(r'WHR$', 'WHR_0', regex=True)\n",
    ")\n",
    "\n",
    "phys_esential.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Occurrences  \n",
    "*This table documents the initial diagnosis dates of different diseases for each participant in the database.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "first_occurences_df = pd.read_csv(os.path.join(path, \"FirstOccurrences_data.tsv\"), sep=\"\\t\")\n",
    "first_occurences_chars_df = pd.read_csv(os.path.join(path, \"FirstOccurrences_chars.tsv\"), sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Population Characteristics  \n",
    "*This table contains data on demographic traits, social factors, and general lifestyle information of the participants.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "popchar_df = pd.read_csv(os.path.join(path, \"popchar_data.tsv\"), sep=\"\\t\")\n",
    "popchar_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Seleccionar columnas relevantes de popchars_df\n",
    "columns_to_keep = ['eid'] + [col for col in popchar_df.columns if re.search(r'_31_|_34_|_52_', col)]\n",
    "popchars_esential = popchar_df[columns_to_keep].copy()\n",
    "\n",
    "# 2. Renombrar columnas\n",
    "popchars_esential.columns = (\n",
    "    popchars_esential.columns\n",
    "    .str.replace('f_31', 'Sex', regex=True)\n",
    "    .str.replace('f_34', 'YearofBirth', regex=True)\n",
    "    .str.replace('f_52', 'MonthofBirth', regex=True)\n",
    "    .str.replace('_0$', '', regex=True)\n",
    ")\n",
    "\n",
    "popchars_esential.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recruitment  \n",
    "*This table includes participant recruitment dates and basic enrollment information.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "recruitment_df = pd.read_csv(os.path.join(path, \"recruitment_data.tsv\"), sep=\"\\t\")\n",
    "recruitment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Touchscreen  \n",
    "*This table contains answers to various touchscreen questionnaires on topics such as health, habits, and lifestyle.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataframes\n",
    "touchscreen_df = pd.read_csv(os.path.join(path, \"touchscreen_data.tsv\"), sep=\"\\t\")\n",
    "touchscreen_chars_df = pd.read_csv(os.path.join(path, \"touchscreen_chars.tsv\"), sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Covariate Selection for IBD  \n",
    "This section aims to identify relevant and significant variables within the UK Biobank data that can serve as covariates in the development of a proteomic biomarker discovery model for Inflammatory Bowel Disease (IBD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Dataset Assembly  \n",
    "This section focuses on merging the proteomic data with the previously identified covariates to generate a final, modeling-ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener todas las fechas del dataset FIRSTOCCURRENCES\n",
    "\n",
    "dates_raw = []\n",
    "\n",
    "# Recolectar todas las fechas únicas de cada columna a partir de la columna 2\n",
    "for col in first_occurences_df.columns[1:]:\n",
    "    unique_vals = first_occurences_df[col].dropna().unique()\n",
    "    dates_raw.extend([str(val) for val in unique_vals])\n",
    "\n",
    "# Quitar duplicados\n",
    "dates_raw = list(set(dates_raw))\n",
    "\n",
    "# Eliminar fechas específicas por posición\n",
    "bad_indices = [19006, 19007, 19008, 19009, 19050]  # Ajustado a base-0\n",
    "dates_raw0 = [date for i, date in enumerate(dates_raw) if i not in bad_indices]\n",
    "\n",
    "# Intentar convertir a formato fechas\n",
    "dates = []\n",
    "failed_dates = []\n",
    "\n",
    "for date_str in dates_raw0:\n",
    "    try:\n",
    "        parsed = pd.to_datetime(date_str, errors='raise')\n",
    "        dates.append(parsed)\n",
    "    except:\n",
    "        failed_dates.append(date_str)\n",
    "\n",
    "# Reintentar con las fallidas\n",
    "for date_str in failed_dates:\n",
    "    try:\n",
    "        parsed = pd.to_datetime(date_str, errors='raise')\n",
    "        dates.append(parsed)\n",
    "    except:\n",
    "        pass  # Puedes guardar las que siguen fallando si quieres analizarlas\n",
    "\n",
    "# Ordenar y eliminar duplicados\n",
    "dates = sorted(set(dates))\n",
    "\n",
    "# Convertir a DataFrame\n",
    "dates_df = pd.DataFrame(dates, columns=['Date'])\n",
    "\n",
    "dates_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtener todas las enfermedades gastrointestinales del dataset FIRSTOCCURRENCES \n",
    "\n",
    "# Obtener el último término de cada jerarquía en la columna 'Path'\n",
    "disease_umbrellas = (\n",
    "    first_occurences_chars_df['Path']\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "# Aplicar transformación a cada string: dividir por '>', invertir, tomar el primero y limpiar espacios\n",
    "disease_umbrellas = [\n",
    "    path.split('>')[-1].strip() for path in disease_umbrellas\n",
    "]\n",
    "\n",
    "# Filtrar por 'Digestive system disorders' y 'Date'\n",
    "digestive_disorders = first_occurences_chars_df[\n",
    "    first_occurences_chars_df['Path'].str.contains('Digestive system disorders', na=False) &\n",
    "    (first_occurences_chars_df['ValueType'] == 'Date')\n",
    "]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "digestive_disorders_df = pd.DataFrame(digestive_disorders)\n",
    "digestive_disorders_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los campos que tienen la enfermedad IBD: UC y CD del dataset FIRSTOCCURRENCES_Chars\n",
    "\n",
    "# Filtrar campos que contienen K52, K50 o K51 en la columna 'Field', y que sean del tipo 'Date'\n",
    "ibd_fields = first_occurences_chars_df[\n",
    "    first_occurences_chars_df['Field'].str.contains('K52|K50|K51', na=False) &\n",
    "    (first_occurences_chars_df['ValueType'] == 'Date')\n",
    "]\n",
    "\n",
    "# Convertir a DataFrame\n",
    "ibd_fields_df = pd.DataFrame(ibd_fields)\n",
    "ibd_fields_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar por individuos que tienen olink del dataset recruitment_data\n",
    "\n",
    "# Filtrar recruitmentdata_raw para quedarse con los individuos con datos Olink, es decir, aquellos que tienen un eid en el dataset de Proteomics\n",
    "olink_recruits = recruitment_df[recruitment_df['eid'].isin(eids)]\n",
    "\n",
    "# Filtrar first_ocurrences también por los mismos IDs del dataset Proteomics\n",
    "olink_first_ocurrences = first_occurences_df[first_occurences_df['eid'].isin(eids)]\n",
    "\n",
    "# Seleccionar la columna FieldID de ibd_fields y conversirla a string\n",
    "field_ids = ibd_fields['FieldID'].astype(str).tolist()\n",
    "\n",
    "# Crear patrón regex: '131626|131628|131630|...'\n",
    "pattern = '|'.join(field_ids)\n",
    "\n",
    "# Filtrar columnas que contienen alguna coincidencia con los IDs + 'eid'\n",
    "columns_to_keep = ['eid'] + [col for col in olink_first_ocurrences.columns if re.search(pattern, col)]\n",
    "\n",
    "# Seleccionar columnas\n",
    "fosid = olink_first_ocurrences[columns_to_keep].copy()\n",
    "\n",
    "# Renombrar columnas: quitar 'f_' y '_0', luego reemplazar IDs por etiquetas\n",
    "fosid.columns = (\n",
    "    fosid.columns\n",
    "    .str.replace('f_', '', regex=False)\n",
    "    .str.replace('_0', '', regex=False)\n",
    "    .str.replace('131626', 'CD', regex=False)\n",
    "    .str.replace('131628', 'UC', regex=False)\n",
    "    .str.replace('131630', 'IBD', regex=False)\n",
    ")\n",
    "\n",
    "\n",
    "fosid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Contar valores no nulos por columna del DataFrame fosid\n",
    "non_na_counts = fosid.notna().sum()\n",
    "\n",
    "# Obtener los IDs únicos de pacientes enfermos con IBD, UC o CD\n",
    "sick = pd.concat([\n",
    "    fosid.loc[fosid['CD'].notna(), 'eid'],\n",
    "    fosid.loc[fosid['UC'].notna(), 'eid'],\n",
    "    fosid.loc[fosid['IBD'].notna(), 'eid']\n",
    "]).unique()\n",
    "\n",
    "#convertir a DataFrame\n",
    "sick_df = pd.DataFrame(sick, columns=['eid'])\n",
    "sick_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar las columnas que están relacionadas con trastornos digestivos\n",
    "\n",
    "# Crear un patrón regex a partir de los FieldIDs \n",
    "pattern = '|'.join(map(str, digestive_disorders['FieldID']))\n",
    "\n",
    "# Seleccionar columnas: 'eid' + aquellas que coincidan con el patrón\n",
    "ddsid = olink_first_ocurrences[['eid'] + [col for col in olink_first_ocurrences.columns if re.search(pattern, col)]]\n",
    "\n",
    "# Conertir a DataFrame\n",
    "ddsid = pd.DataFrame(ddsid)\n",
    "ddsid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde todas las columnas excepto 'eid' son NA\n",
    "\n",
    "digestive_cols = ddsid.columns.drop('eid')\n",
    "mask = ddsid[digestive_cols].isna().sum(axis=1) == len(digestive_cols)\n",
    "popcontrols = ddsid[mask]\n",
    "\n",
    "# Obtener los Ids de los controles poblacionales (Sin enfermedades digestivas)\n",
    "popcontrolsids = popcontrols['eid'].values\n",
    "\n",
    "# Convertir a DataFrame\n",
    "popcontrolsids_df = pd.DataFrame(popcontrolsids, columns=['eid'])\n",
    "popcontrolsids_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Seleccionar columnas específicas de olink_recruits\n",
    "timestamps = olink_recruits.loc[:, [\n",
    "    'eid',\n",
    "    'f_53_0_0', 'f_53_1_0', 'f_53_2_0', 'f_53_3_0',\n",
    "    'f_21003_0_0', 'f_21003_1_0', 'f_21003_2_0', 'f_21003_3_0',\n",
    "    'f_54_0_0'\n",
    "]].copy()\n",
    "\n",
    "# Renombrar columnas de interes\n",
    "timestamps.columns = [\n",
    "    'eid', 'TM1', 'TM2', 'TM3', 'TM4',\n",
    "    'Age1', 'Age2', 'Age3', 'Age4',\n",
    "    'AssessmentCentre'\n",
    "]\n",
    "\n",
    "# Hacer merge con fosid por 'eid'\n",
    "infodata = pd.merge(fosid, timestamps, on='eid', how='left')\n",
    "\n",
    "infodata.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir las columnas de fecha a tipo datetime\n",
    "date_cols = ['CD', 'UC', 'IBD', 'TM1', 'TM2', 'TM3', 'TM4']\n",
    "infodata[date_cols] = infodata[date_cols].apply(pd.to_datetime, errors='coerce')\n",
    "\n",
    "# Crear nuevas columnas con la diferencia en días\n",
    "infodata['CD2T1'] = (infodata['CD'] - infodata['TM1']).dt.days\n",
    "infodata['CD2T2'] = (infodata['CD'] - infodata['TM2']).dt.days\n",
    "infodata['CD2T3'] = (infodata['CD'] - infodata['TM3']).dt.days\n",
    "infodata['CD2T4'] = (infodata['CD'] - infodata['TM4']).dt.days\n",
    "\n",
    "infodata['UC2T1'] = (infodata['UC'] - infodata['TM1']).dt.days\n",
    "infodata['UC2T2'] = (infodata['UC'] - infodata['TM2']).dt.days\n",
    "infodata['UC2T3'] = (infodata['UC'] - infodata['TM3']).dt.days\n",
    "infodata['UC2T4'] = (infodata['UC'] - infodata['TM4']).dt.days\n",
    "\n",
    "infodata['IBD2T1'] = (infodata['IBD'] - infodata['TM1']).dt.days\n",
    "infodata['IBD2T2'] = (infodata['IBD'] - infodata['TM2']).dt.days\n",
    "infodata['IBD2T3'] = (infodata['IBD'] - infodata['TM3']).dt.days\n",
    "infodata['IBD2T4'] = (infodata['IBD'] - infodata['TM4']).dt.days\n",
    "\n",
    "# Guardar como nuevo DataFrame \n",
    "infodata0 = infodata.copy()\n",
    "\n",
    "# Dataframe\n",
    "infodata0_df = pd.DataFrame(infodata0)\n",
    "infodata0_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcular variables tiempo relativo a diagnóstico\n",
    "for disease in ['CD', 'UC', 'IBD']:\n",
    "    for timepoint in ['TM1', 'TM2', 'TM3', 'TM4']:\n",
    "        infodata[f'{disease}2{timepoint}'] = (infodata[disease] - infodata[timepoint]).dt.days\n",
    "\n",
    "\n",
    "# Pivotear las columnas CD, UC, IBD a formato largo\n",
    "infodata_long = infodata.melt(\n",
    "    id_vars=[col for col in infodata.columns if col not in ['CD', 'UC', 'IBD']],\n",
    "    value_vars=['CD', 'UC', 'IBD'],\n",
    "    var_name='Disease',\n",
    "    value_name='DiagnosedAt'\n",
    ")\n",
    "\n",
    "# Calcular diferencias DxTM1 a DxTM4 (días entre diagnóstico y visitas TM) \n",
    "for i in range(1, 5):\n",
    "    infodata_long[f'DxTM{i}'] = (pd.to_datetime(infodata_long['DiagnosedAt'], errors='coerce') -\n",
    "                                pd.to_datetime(infodata_long[f'TM{i}'], errors='coerce')).dt.days\n",
    "\n",
    "# Crear categorías Pre/Post diagnóstico\n",
    "for i in range(1, 5):\n",
    "    infodata_long[f'TCategory{i}'] = np.where(\n",
    "        infodata_long[f'DxTM{i}'] < 0,\n",
    "        'Pre-diagnosis',\n",
    "        'Post-diagnosis'\n",
    "    )\n",
    "\n",
    "# Pivotear para reorganizar variables TM, Age, DxTM, TCategory con número de visita \n",
    "# Primero, hacemos melt dejando columnas fijas\n",
    "id_vars = ['eid', 'Disease', 'DiagnosedAt', 'AssessmentCentre'] + [col for col in infodata_long.columns if not any(s in col for s in ['TM', 'Age', 'DxTM', 'TCategory'])]\n",
    "melt_vars = [col for col in infodata_long.columns if any(s in col for s in ['TM', 'Age', 'DxTM', 'TCategory'])]\n",
    "\n",
    "# Para simplicidad, hacemos melt explícito con esas columnas:\n",
    "cols_to_melt = ['TM1', 'TM2', 'TM3', 'TM4',\n",
    "                'Age1', 'Age2', 'Age3', 'Age4',\n",
    "                'DxTM1', 'DxTM2', 'DxTM3', 'DxTM4',\n",
    "                'TCategory1', 'TCategory2', 'TCategory3', 'TCategory4']\n",
    "\n",
    "df_melt = infodata_long.melt(\n",
    "    id_vars=['eid', 'Disease', 'DiagnosedAt', 'AssessmentCentre'],\n",
    "    value_vars=cols_to_melt,\n",
    "    var_name='VariableTime',\n",
    "    value_name='Value'\n",
    ")\n",
    "\n",
    "# Extraer nombre base y número de visita\n",
    "df_melt[['Variable', 'Times']] = df_melt['VariableTime'].str.extract(r'([A-Za-z]+)(\\d+)')\n",
    "\n",
    "# Pivot para expandir variables a columnas\n",
    "infodata1 = df_melt.pivot_table(\n",
    "    index=['eid', 'Disease', 'DiagnosedAt', 'AssessmentCentre', 'Times'],\n",
    "    columns='Variable',\n",
    "    values='Value',\n",
    "    aggfunc='first'\n",
    ").reset_index()\n",
    "\n",
    "# Reordenar columnas \n",
    "cols_order = ['eid', 'Disease', 'DiagnosedAt', 'AssessmentCentre', 'Times', 'Age', 'TM', 'DxTM', 'TCategory']\n",
    "infodata1 = infodata1[cols_order]\n",
    "\n",
    "# Convertir a datetime\n",
    "infodata1_df = pd.DataFrame(infodata1)\n",
    "infodata1_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas con eid en 'sick' y al menos un tiempo relativo a diagnóstico positivo (>0)\n",
    "mask_sick = infodata0['eid'].isin(sick)\n",
    "time_cols = ['CD2T1','CD2T2','CD2T3','CD2T4','UC2T1','UC2T2','UC2T3','UC2T4','IBD2T1','IBD2T2','IBD2T3','IBD2T4']\n",
    "\n",
    "# Crear una máscara que chequea si alguna de las columnas time_cols es > 0\n",
    "mask_time_positive = infodata0[time_cols].gt(0).any(axis=1)\n",
    "sickdb = infodata0.loc[mask_sick & mask_time_positive]\n",
    "\n",
    "\n",
    "# Filtrar sick + controles poblacionales\n",
    "combined_array = np.concatenate((sick, popcontrolsids))\n",
    "\n",
    "mask_sickpopcon = infodata0['eid'].isin(combined_array)\n",
    "sickpopcon = infodata0.loc[mask_sickpopcon]\n",
    "sickpopcon = infodata0.loc[mask_sickpopcon]\n",
    "\n",
    "# Solo controles poblacionales\n",
    "mask_popcon = infodata0['eid'].isin(popcontrolsids)\n",
    "pocon = infodata0.loc[mask_popcon]\n",
    "\n",
    "# Filtrar filas donde CD no es NA (no nulo)\n",
    "sickpopcon_cd = sickpopcon.loc[sickpopcon['CD'].notna()]\n",
    "infodata0_cd = infodata0.loc[infodata0['CD'].notna()]\n",
    "cds = infodata0.loc[infodata0['CD'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar subset de personas con diagnóstico exclusivo\n",
    "\n",
    "cds_only = sickpopcon.loc[\n",
    "    sickpopcon['CD'].notna() &\n",
    "    sickpopcon['UC'].isna() &\n",
    "    sickpopcon['IBD'].isna()\n",
    "]\n",
    "\n",
    "uc_only = sickpopcon.loc[\n",
    "    sickpopcon['UC'].notna() &\n",
    "    sickpopcon['CD'].isna() &\n",
    "    sickpopcon['IBD'].isna()\n",
    "]\n",
    "\n",
    "ibd_only = sickpopcon.loc[\n",
    "    sickpopcon['IBD'].notna() &\n",
    "    sickpopcon['CD'].isna() &\n",
    "    sickpopcon['UC'].isna()\n",
    "]\n",
    "\n",
    "uc_ibd_only = sickpopcon.loc[\n",
    "    sickpopcon['UC'].notna() &\n",
    "    sickpopcon['IBD'].notna() &\n",
    "    sickpopcon['CD'].isna()\n",
    "]\n",
    "\n",
    "cd_ibd_only = sickpopcon.loc[\n",
    "    sickpopcon['CD'].notna() &\n",
    "    sickpopcon['IBD'].notna() &\n",
    "    sickpopcon['UC'].isna()\n",
    "]\n",
    "\n",
    "# Filtrar cds_only donde TM2, TM3 y TM4 sean NA\n",
    "cds_only_missing_TM234 = cds_only.loc[\n",
    "    cds_only['TM2'].isna() &\n",
    "    cds_only['TM3'].isna() &\n",
    "    cds_only['TM4'].isna()\n",
    "]\n",
    "\n",
    "# Combinar con controles poblacionales (pocon)\n",
    "cds_popc = pd.concat([cds_only, pocon], ignore_index=True)\n",
    "uc_popc = pd.concat([uc_only, pocon], ignore_index=True)\n",
    "ibd_popc = pd.concat([ibd_only, pocon], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Crear lista de eids con solo enfermedad CD, UC o IBD\n",
    "disease_only_eids = pd.concat([cds_only['eid'], uc_only['eid'], ibd_only['eid']]).unique()\n",
    "\n",
    "# Combinar los grupos ibd_only, cds_only, uc_only y controles poblacionales (pocon)\n",
    "disease_popc = pd.concat([ibd_only, cds_only, uc_only, pocon], ignore_index=True)\n",
    "\n",
    "# Seleccionar columnas específicas en disease_popc (similar a select)\n",
    "cols_of_interest = ['eid', 'CD', 'UC', 'IBD', 'TM1', 'Age1', 'AssessmentCentre', 'CD2T1', 'UC2T1', 'IBD2T1']\n",
    "disease_popc_0 = disease_popc.loc[:, cols_of_interest]\n",
    "\n",
    "#Filtrar solo con los pacientes\n",
    "donly = infodata1.loc[infodata1['eid'].isin(disease_only_eids)]\n",
    "\n",
    "#Tablas de conteos \n",
    "# Conteo categorías en la visita Times=2 por enfermedad\n",
    "print(donly.loc[(donly['Disease'] == 'CD') & (donly['Times'] == '2'), 'TCategory'].value_counts())\n",
    "print(donly.loc[(donly['Disease'] == 'UC') & (donly['Times'] == '2'), 'TCategory'].value_counts())\n",
    "print(donly.loc[(donly['Disease'] == 'IBD') & (donly['Times'] == '2'), 'TCategory'].value_counts())\n",
    "\n",
    "#Identificar IDs con post-diagnóstico en la primera visita y filtrar pre-diagnóstico en otras visitas\n",
    "t1post = donly.loc[\n",
    "    (donly['Disease'] == 'IBD') & (donly['Times'] == '1') & (donly['TCategory'] == 'Post-diagnosis'),\n",
    "    'eid'\n",
    "].unique()\n",
    "\n",
    "#Contar filas donde para esos eid, en otras visitas no 1, la categoría sea Pre-diagnosis\n",
    "count_pre_other_times = donly.loc[\n",
    "    (donly['eid'].isin(t1post)) &\n",
    "    (donly['Disease'] == 'IBD') &\n",
    "    (donly['Times'] != '1') &\n",
    "    (donly['TCategory'] == 'Pre-diagnosis')\n",
    "].shape[0]\n",
    "\n",
    "#Filtrar ibd_popc con IBD NA\n",
    "ibd_na = ibd_popc.loc[ibd_popc['IBD'].isna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe ibd con nuevas variables y joins\n",
    "# Crear columna Disease con prioridad CD > UC > IBD > Control\n",
    "def classify_disease(row):\n",
    "    if pd.notna(row['CD']):\n",
    "        return 'CD'\n",
    "    elif pd.notna(row['UC']):\n",
    "        return 'UC'\n",
    "    elif pd.notna(row['IBD']):\n",
    "        return 'IBD'\n",
    "    else:\n",
    "        return 'Control'\n",
    "\n",
    "ibd = disease_popc_0.copy()\n",
    "ibd['Disease'] = ibd.apply(classify_disease, axis=1)\n",
    "\n",
    "# Crear columna Time_Category según IBD2T1\n",
    "ibd['Time_Category'] = np.where(ibd['IBD2T1'] < 0, 'Pre-diagnosis', 'Post-diagnosis')\n",
    "ibd.loc[ibd['Time_Category'].isna(), 'Time_Category'] = 'Control'\n",
    "\n",
    "# Convertir Time_Category a categoría ordenada según valores únicos ordenados\n",
    "unique_levels = sorted(ibd['Time_Category'].dropna().unique())\n",
    "ibd['Time_Category'] = pd.Categorical(ibd['Time_Category'], categories=unique_levels, ordered=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVARIABLES\n",
    "\n",
    "\n",
    "# Hacer left joins (merge) por eid con otros dataframes productos de la covariable selection \n",
    "# Join con phenodata_esential_df\n",
    "ibd = ibd.merge(phenodata_esential_df, on='eid', how='left')\n",
    "\n",
    "# join with PCAS form genomics\n",
    "pc_columns = ['eid'] + [f'PC_{i}' for i in range(1,6)]\n",
    "ibd = ibd.merge(etnicidad_df.loc[:, pc_columns], on='eid', how='left')\n",
    "\n",
    "# Join con olinkdata\n",
    "ibd = ibd.merge(Proteomics_df, on='eid', how='left')\n",
    "\n",
    "# Convertimos los nombres de columnas a string\n",
    "ibd.columns = ibd.columns.astype(str)\n",
    "\n",
    "# Seleccionar primeras 12 columnas y columnas con PC_ y que terminen en '_0', excepto algunas columnas excluidas\n",
    "cols = list(ibd.columns[:12]) # primeras 12 column\n",
    "\n",
    "# Columnas con 'PC_'\n",
    "cols += [col for col in ibd.columns if 'PC_' in col]\n",
    "\n",
    "# Columnas que terminan en '_0', excluyendo algunas específicas\n",
    "cols_0 = [col for col in ibd.columns if col.endswith('_0')]\n",
    "exclude_cols = ['WHR_0', 'BMI_0', 'YearOfBirth_0', 'MonthOfBirth_0']\n",
    "cols_0_filtered = [col for col in cols_0 if col not in exclude_cols]\n",
    "\n",
    "# Concatenar todas las columnas finales\n",
    "cols += cols_0_filtered\n",
    "\n",
    "# Subset final\n",
    "ibd0 = ibd[cols].copy()\n",
    "\n",
    "# Asegurar que Time_Category tenga orden correcto\n",
    "ibd0['Time_Category'] = pd.Categorical(\n",
    "    ibd0['Time_Category'],\n",
    "    categories=['Control', 'Pre-diagnosis', 'Post-diagnosis'],\n",
    "    ordered=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardar el dataframe final\n",
    "#NO ESTAN SALIENDO LAS COLUMNAS DE LOS DIFERENTES TIEMPOS QUE ESTAN EN INFODATA0\n",
    "ibd0.to_csv(os.path.join(path, \"ibd_final_data.tsv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preprocessing (Raw to Tidy)  \n",
    "Preprocessing of the merged dataset, including NA handling, outlier removal, and variable transformations to obtain a tidy and consistent format for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo correcto es tratar cada proteína individualmente\n",
    "\n",
    "#Porque:\n",
    "#-Cada proteína tiene distinta dispersión y rango.\n",
    "#-Los outliers son específicos por variable, y afectan interpretaciones clínicas.\n",
    "#-Muchas técnicas de reducción de dimensión, clustering o modelos multivariantes asumen datos limpios por variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el DataFrame\n",
    "ibd0 = pd.read_csv(os.path.join(path, \"ibd_final_data.tsv\"), sep=\",\")\n",
    "\n",
    "\n",
    "# Columnas a excluir\n",
    "cols_excluir = ['Smoking_0', 'Alcohol_0']\n",
    "\n",
    "# Seleccionar columnas que terminan en '_0' pero excluyendo las que no quieres\n",
    "cols_0_filtradas = [col for col in ibd0.columns if col.endswith('_0') and col not in cols_excluir]\n",
    "\n",
    "# Agregar explícitamente 'disease' si está en el DataFrame\n",
    "if 'Disease' in ibd0.columns:\n",
    "    cols_0_filtradas.append('Disease')\n",
    "if 'Time_Category' in ibd0.columns:\n",
    "    cols_0_filtradas.append('Time_Category')    \n",
    "\n",
    "# Filtrar el DataFrame\n",
    "ibd0_filtrado = ibd0[cols_0_filtradas]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la distribución de las proteínas y guardar la figura generada\n",
    "\n",
    "visualizaciones.graficar_distribucion_proteinas(\n",
    "    proteinas=ibd0_filtrado,\n",
    "    path=path_graphs,\n",
    "    clase='Disease',\n",
    "    nombre='Distribución_de_Proteínas_por_Enfermedad.pdf',\n",
    "    mostrar=False,\n",
    ");\n",
    "\n",
    "print(\"Distribución de proteínas por enfermedad guardada en la carpeta de gráficos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar columnas con más del 80% de NAs\n",
    "\n",
    "# Calculo de NAs por columna\n",
    "countnas = ibd0_filtrado.isna().sum()\n",
    "\n",
    "# Mostrar porcentaje de NAs por columna en un DataFrame, ordenado descendente\n",
    "percent_nas = pd.DataFrame(ibd0_filtrado.isna().mean() * 100, columns=['Percent_NA'])\n",
    "percent_nas_sorted = percent_nas.sort_values(by='Percent_NA', ascending=False)\n",
    "\n",
    "ibd0_filtrado_clean= limpieza.eliminar_nas_col(ibd0_filtrado, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar outliers usando el método IQR\n",
    "ibd0_filtrado_sin_outliers = limpieza.eliminar_outliers_iqr(ibd0_filtrado_clean)\n",
    "ibd0_filtrado_sin_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar cada proteína dependiendo de su asimetria, \n",
    "ibd0_normalizado = transformaciones.normalizar_proteinas(ibd0_filtrado_sin_outliers, clase='Disease')\n",
    "ibd0_normalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar nuevamente las distribuciones de las proteínas transformadas y guardar la figura generada\n",
    "\n",
    "visualizaciones.graficar_distribucion_proteinas(\n",
    "    proteinas=ibd0_normalizado,\n",
    "    path=path_graphs,\n",
    "    clase='Disease',\n",
    "    nombre='Distribución_de_Proteínas_Normalizadas_por_Enfermedad.pdf',\n",
    "    mostrar=False,\n",
    ")\n",
    "\n",
    "print(\"Distribución de proteínas normalizadas por enfermedad guardada en la carpeta de gráficos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los boxplots de las proteínas y guardar la figura generada\n",
    "visualizaciones.graficar_boxplots_proteinas(\n",
    "    df=ibd0_filtrado,\n",
    "    path=path_graphs,\n",
    "    clase_x='Disease',\n",
    "    hue=\"Time_Category\",\n",
    "    nombre='Boxplot_de_Proteinas.pdf',\n",
    "    mostrar=False,\n",
    ")\n",
    "\n",
    "print(\"Boxplot de proteínas guardado en la carpeta de gráficos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar los boxplots de las proteínas normalizadas y guardar la figura generada\n",
    "visualizaciones.graficar_boxplots_proteinas(\n",
    "    df=ibd0_normalizado,\n",
    "    path=path_graphs,\n",
    "    clase_x='Disease',\n",
    "    hue=\"Time_Category\",\n",
    "    nombre='Boxplot_de_Proteinas_normalizadas.pdf',\n",
    "    mostrar=False,\n",
    ")\n",
    "\n",
    "print(\"Boxplot de proteínas normalizadas guardado en la carpeta de gráficos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Visualizations  \n",
    "This section presents key plots for interpreting data structure, group differences, and model insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Funcion ejemplo para plotear longitudinalmente\n",
    "\n",
    "\n",
    "# Supongamos que `dat` es tu DataFrame equivalente a cds_only\n",
    "\n",
    "# Por ejemplo, plotear edad en función del tiempo relativo al diagnóstico (YearsRelativeToDx),\n",
    "# con puntos separados por eid (pacientes) o Disease si hay más\n",
    "\n",
    "#plt.figure(figsize=(10,6))\n",
    "#sns.scatterplot(\n",
    "#    data=ibd0,\n",
    "#    x='YearsRelativeToDx',  # o la variable de tiempo que tengas\n",
    "#    y='Age',                # o variable que quieras visualizar\n",
    "#    hue='eid',              # colorear por paciente, si hay muchos puedes omitir\n",
    "#    s=30                    # tamaño de puntos, ajusta a psize=1.5 como sea necesario\n",
    "#)\n",
    "\n",
    "#plt.title('Diagnoses timeline CDs Only')\n",
    "#plt.xlabel('Years Relative to Diagnosis')\n",
    "#plt.ylabel('Age')\n",
    "\n",
    "#plt.legend([],[], frameon=False)  # oculta leyenda si muchos ids\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear variables anuales para cada enfermedad\n",
    "ibd0['UC2T1_years'] = ibd0['UC2T1'] / 365.25\n",
    "ibd0['IBD2T1_years'] = ibd0['IBD2T1'] / 365.25\n",
    "ibd0['CD2T1_years'] = ibd0['CD2T1'] / 365.25\n",
    "ibd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diagnoses timeline IBD patients, tiempo relativo al diagnóstico\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=ibd0,\n",
    "    x='IBD2T1_years',\n",
    "    y='Age1',           # o 'Age', si así se llama la edad en tu df\n",
    "    hue='eid',          # puedes usar 'Disease' si prefieres menos colores\n",
    "    s=30\n",
    ")\n",
    "\n",
    "plt.title('Diagnoses timeline IBD patients')\n",
    "plt.xlabel('Years Relative to Diagnosis')\n",
    "plt.ylabel('Age at Measurement')\n",
    "\n",
    "plt.legend([], [], frameon=False)  # Oculta la leyenda si hay muchos 'eid'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Diagnoses timeline CD patients, tiempo relativo al diagnóstico\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=ibd0,\n",
    "    x='CD2T1_years',\n",
    "    y='Age1',           # o 'Age', si así se llama la edad en tu df\n",
    "    hue='eid',          # puedes usar 'Disease' si prefieres menos colores\n",
    "    s=30\n",
    ")\n",
    "\n",
    "plt.title('Diagnoses timeline CD patients')\n",
    "plt.xlabel('Years Relative to Diagnosis')\n",
    "plt.ylabel('Age at Measurement')\n",
    "\n",
    "plt.legend([], [], frameon=False)  # Oculta la leyenda si hay muchos 'eid'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Diagnoses timeline UC patients, tiempo relativo al diagnóstico\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=ibd0,\n",
    "    x='UC2T1_years',\n",
    "    y='Age1',           # o 'Age', si así se llama la edad en tu df\n",
    "    hue='eid',          # puedes usar 'Disease' si prefieres menos colores\n",
    "    s=30\n",
    ")\n",
    "\n",
    "plt.title('Diagnoses timeline UC patients')\n",
    "plt.xlabel('Years Relative to Diagnosis')\n",
    "plt.ylabel('Age at Measurement')\n",
    "\n",
    "plt.legend([], [], frameon=False)  # Oculta la leyenda si hay muchos 'eid'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Models  \n",
    "Here we fit and evaluate various models for IBD biomarker discovery using proteomic and covariate data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Logistic Regression per Protein - Biomarker detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MetaAnalysis Between Cohorts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Survival analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Association Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: AI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
